{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ea7740",
   "metadata": {},
   "source": [
    "# Lab10 (Instructor) — Solutions & Checks\n",
    "\n",
    "Notebook นี้มีแนวคำตอบและจุดตรวจ (sanity checks) สำหรับผู้สอน\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcdf1139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/jovyan/work/notebooks\n",
      "Data path: ../data\n",
      "Data path exists: True\n",
      "\n",
      "Loaded data shapes:\n",
      "df_tx: (1000, 3), columns: ['TransactionID', 'Amount', 'CustomerID']\n",
      "df_meta: (1000, 3), columns: ['TransactionID', 'Timestamp', 'MerchantID']\n",
      "df_cust: (1000, 4), columns: ['CustomerID', 'Name', 'Age', 'Address']\n",
      "df_act: (1000, 3), columns: ['CustomerID', 'AccountBalance', 'LastLogin']\n",
      "df_fraud: (1000, 2), columns: ['TransactionID', 'FraudIndicator']\n",
      "\n",
      "After merge with meta: (1000, 5), columns: ['TransactionID', 'Amount', 'CustomerID', 'Timestamp', 'MerchantID']\n",
      "After merge with cust: (1000, 8), columns: ['TransactionID', 'Amount', 'CustomerID', 'Timestamp', 'MerchantID', 'Name', 'Age', 'Address']\n",
      "After merge with act: (1000, 10), columns: ['TransactionID', 'Amount', 'CustomerID', 'Timestamp', 'MerchantID', 'Name', 'Age', 'Address', 'AccountBalance', 'LastLogin']\n",
      "After merge with merch: (1000, 12)\n",
      "After merge with fraud: (1000, 13)\n",
      "All columns: ['TransactionID', 'Amount', 'CustomerID', 'Timestamp', 'MerchantID', 'Name', 'Age', 'Address', 'AccountBalance', 'LastLogin', 'MerchantName', 'Location', 'FraudIndicator']\n",
      "\n",
      "Creating time-based features...\n",
      "DaysSinceLastLogin created: True\n",
      "Creating transaction count feature...\n",
      "Creating amount-based features...\n",
      "AnomalyScore created: True\n",
      "\n",
      "All columns after feature creation:\n",
      "['TransactionID', 'Amount', 'CustomerID', 'Timestamp', 'MerchantID', 'Name', 'Age', 'Address', 'AccountBalance', 'LastLogin', 'MerchantName', 'Location', 'FraudIndicator', 'IsFraud', 'Hour', 'ts_hour', 'DaysSinceLastLogin', 'TxCount_1h', 'AmountToCustomerAvg', 'AnomalyScore']\n",
      "\n",
      "Features to use: ['Amount', 'AnomalyScore', 'Age', 'AccountBalance', 'Hour', 'DaysSinceLastLogin', 'TxCount_1h', 'AmountToCustomerAvg']\n",
      "Missing features: []\n",
      "\n",
      "Class balance:\n",
      "IsFraud\n",
      "0    0.955\n",
      "1    0.045\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "X shape: (1000, 8)\n",
      "y shape: (1000,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>AnomalyScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>AccountBalance</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DaysSinceLastLogin</th>\n",
       "      <th>TxCount_1h</th>\n",
       "      <th>AmountToCustomerAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.530334</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>50</td>\n",
       "      <td>2869.689912</td>\n",
       "      <td>0</td>\n",
       "      <td>-951</td>\n",
       "      <td>1</td>\n",
       "      <td>1.016907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.881180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>9527.947107</td>\n",
       "      <td>1</td>\n",
       "      <td>-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.176322</td>\n",
       "      <td>0.027284</td>\n",
       "      <td>34</td>\n",
       "      <td>9288.355525</td>\n",
       "      <td>2</td>\n",
       "      <td>-954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.634001</td>\n",
       "      <td>0.164801</td>\n",
       "      <td>33</td>\n",
       "      <td>5588.049942</td>\n",
       "      <td>3</td>\n",
       "      <td>-795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.122853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>7324.785332</td>\n",
       "      <td>4</td>\n",
       "      <td>-945</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Amount  AnomalyScore  Age  AccountBalance  Hour  DaysSinceLastLogin  \\\n",
       "0  55.530334      0.016907   50     2869.689912     0                -951   \n",
       "1  12.881180      0.000000   46     9527.947107     1                 -26   \n",
       "2  50.176322      0.027284   34     9288.355525     2                -954   \n",
       "3  41.634001      0.164801   33     5588.049942     3                -795   \n",
       "4  78.122853      0.000000   18     7324.785332     4                -945   \n",
       "\n",
       "   TxCount_1h  AmountToCustomerAvg  \n",
       "0           1             1.016907  \n",
       "1           1             1.000000  \n",
       "2           1             0.972716  \n",
       "3           1             0.835199  \n",
       "4           1             1.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Check current directory and data path\n",
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "DATA = Path('..') / 'data'\n",
    "print(\"Data path:\", DATA)\n",
    "print(\"Data path exists:\", DATA.exists())\n",
    "print()\n",
    "\n",
    "# Load data\n",
    "df_tx = pd.read_csv(DATA / 'Transaction Data' / 'transaction_records.csv')\n",
    "df_meta = pd.read_csv(DATA / 'Transaction Data' / 'transaction_metadata.csv')\n",
    "df_cust = pd.read_csv(DATA / 'Customer Profiles' / 'customer_data.csv')\n",
    "df_act = pd.read_csv(DATA / 'Customer Profiles' / 'account_activity.csv')\n",
    "df_merch = pd.read_csv(DATA / 'Merchant Information' / 'merchant_data.csv')\n",
    "df_fraud = pd.read_csv(DATA / 'Fraudulent Patterns' / 'fraud_indicators.csv')\n",
    "\n",
    "print(\"Loaded data shapes:\")\n",
    "print(f\"df_tx: {df_tx.shape}, columns: {list(df_tx.columns)}\")\n",
    "print(f\"df_meta: {df_meta.shape}, columns: {list(df_meta.columns)}\")\n",
    "print(f\"df_cust: {df_cust.shape}, columns: {list(df_cust.columns)}\")\n",
    "print(f\"df_act: {df_act.shape}, columns: {list(df_act.columns)}\")\n",
    "print(f\"df_fraud: {df_fraud.shape}, columns: {list(df_fraud.columns)}\")\n",
    "print()\n",
    "\n",
    "# Merge all data\n",
    "df = df_tx.merge(df_meta, on='TransactionID', how='left')\n",
    "print(f\"After merge with meta: {df.shape}, columns: {list(df.columns)}\")\n",
    "\n",
    "df = df.merge(df_cust, on='CustomerID', how='left')\n",
    "print(f\"After merge with cust: {df.shape}, columns: {list(df.columns)}\")\n",
    "\n",
    "df = df.merge(df_act, on='CustomerID', how='left')\n",
    "print(f\"After merge with act: {df.shape}, columns: {list(df.columns)}\")\n",
    "\n",
    "df = df.merge(df_merch, on='MerchantID', how='left')\n",
    "print(f\"After merge with merch: {df.shape}\")\n",
    "\n",
    "df = df.merge(df_fraud[['TransactionID','FraudIndicator']], on='TransactionID', how='left')\n",
    "print(f\"After merge with fraud: {df.shape}\")\n",
    "print(f\"All columns: {list(df.columns)}\")\n",
    "print()\n",
    "\n",
    "# Create features\n",
    "df['IsFraud'] = df['FraudIndicator'].fillna(0).astype(int)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "df['LastLogin'] = pd.to_datetime(df['LastLogin'], errors='coerce')\n",
    "\n",
    "print(\"Creating time-based features...\")\n",
    "df['Hour'] = df['Timestamp'].dt.hour.fillna(0).astype(int)\n",
    "df['ts_hour'] = df['Timestamp'].dt.floor('H')\n",
    "df['DaysSinceLastLogin'] = (df['Timestamp'] - df['LastLogin']).dt.days.fillna(0).astype(int)\n",
    "print(f\"DaysSinceLastLogin created: {('DaysSinceLastLogin' in df.columns)}\")\n",
    "\n",
    "print(\"Creating transaction count feature...\")\n",
    "df['TxCount_1h'] = df.groupby(['CustomerID','ts_hour'])['TransactionID'].transform('count')\n",
    "\n",
    "print(\"Creating amount-based features...\")\n",
    "cust_avg = df.groupby('CustomerID')['Amount'].transform('mean')\n",
    "df['AmountToCustomerAvg'] = (df['Amount'] / cust_avg).replace([float('inf')], 0).fillna(0)\n",
    "df['AnomalyScore'] = ((df['Amount'] - cust_avg) / cust_avg).abs().fillna(0)\n",
    "print(f\"AnomalyScore created: {('AnomalyScore' in df.columns)}\")\n",
    "print()\n",
    "\n",
    "print(\"All columns after feature creation:\")\n",
    "print(list(df.columns))\n",
    "print()\n",
    "\n",
    "features = ['Amount','AnomalyScore','Age','AccountBalance','Hour','DaysSinceLastLogin','TxCount_1h','AmountToCustomerAvg']\n",
    "print(f\"Features to use: {features}\")\n",
    "print(f\"Missing features: {[f for f in features if f not in df.columns]}\")\n",
    "\n",
    "X = df[features].fillna(0)\n",
    "y = df['IsFraud']\n",
    "\n",
    "print(\"\\nClass balance:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1d0c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.956     1.000     0.978       239\n",
      "           1      0.000     0.000     0.000        11\n",
      "\n",
      "    accuracy                          0.956       250\n",
      "   macro avg      0.478     0.500     0.489       250\n",
      "weighted avg      0.914     0.956     0.934       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0659c009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using API: http://api:8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'trained',\n",
       " 'n_rows': 1000,\n",
       " 'label_fraud_rate': 0.045,\n",
       " 'balanced_fraud_rate': 0.5,\n",
       " 'train_samples': 216,\n",
       " 'cv_folds': 5,\n",
       " 'cv_confusion_matrix': [[493, 271], [21, 15]],\n",
       " 'cv_precision': 0.05221049009105215,\n",
       " 'cv_recall': 0.42142857142857143,\n",
       " 'cv_f1': 0.09273604635711372,\n",
       " 'cv_roc_auc': 0.5508807250970563,\n",
       " 'test_confusion_matrix': [[118, 73], [4, 5]],\n",
       " 'test_precision': 0.0641025641025641,\n",
       " 'test_recall': 0.5555555555555556,\n",
       " 'test_f1': 0.11494252873563218,\n",
       " 'notes': 'IsolationForest (unsupervised). Ensemble (RF+GB) with hybrid balancing (undersample majority + SMOTE oversample minority). Using 5-Fold Stratified CV with threshold=0.30 for balanced evaluation.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API smoke test\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Use 'api' service name when running in Docker, 'localhost' otherwise\n",
    "API = 'http://api:8000' if os.path.exists('/.dockerenv') else 'http://localhost:8000'\n",
    "print(f\"Using API: {API}\")\n",
    "\n",
    "response = requests.post(f'{API}/fraud/train')\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e174b26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'iforest_decision_function': -0.0015144684414128973,\n",
       "  'iforest_risk_score': 0.0015144684414128973,\n",
       "  'shadow_model_pred': 1,\n",
       "  'shadow_model_proba': 0.2739542477340603},\n",
       " {'method': 'value_magnitude',\n",
       "  'top_factors': [{'feature': 'DaysSinceLastLogin',\n",
       "    'contribution': 1.5949386622572366},\n",
       "   {'feature': 'DayOfWeek', 'contribution': -1.476168840844461},\n",
       "   {'feature': 'Age', 'contribution': -1.4272816261966899},\n",
       "   {'feature': 'Hour', 'contribution': -1.3737346025734039},\n",
       "   {'feature': 'AnomalyScore', 'contribution': -1.0815420780362677}],\n",
       "  'note': 'Basic feature value magnitude ranking.'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = requests.get(f'{API}/fraud/top', params={'limit':5}).json()['items']\n",
    "tx_id = int(top[0]['TransactionID'])\n",
    "score = requests.post(f'{API}/fraud/score', json={'transaction_id': tx_id}).json()\n",
    "explain = requests.post(f'{API}/fraud/explain', json={'transaction_id': tx_id, 'top_k': 5}).json()\n",
    "score, explain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
